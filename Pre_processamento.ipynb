{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-processamento.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabgovar/RNP_PyTorch/blob/main/Pre_processamento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Créditos\n",
        "\n",
        "O conteúdo deste notebook usa material das seguintes fontes:\n",
        "\n",
        "- [Deep Learning Wizard](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/)\n",
        "\n",
        "- [Deep Learning with PyTorch: Zero to GANs](https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans)\n",
        "\n",
        "- [Machine Learning Glossary](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)"
      ],
      "metadata": {
        "id": "0VTuDuUrq3fl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMNlhyt2h-AH"
      },
      "source": [
        "# Regressão Linear\n",
        "\n",
        "Nesta seção, vamos resolver um problema de regressão linear tentando usar classes fornecidas pelo PyTorch para manipulação de conjuntos de dados. Vamos perceber que o PyTorch fornece a implementação de diversas partes do *pipeline* de treinamento de uma rede neural artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT8PKx981tac"
      },
      "source": [
        "## Armazenamento de dados em tensores\n",
        "\n",
        "Uma operação bastante comum é fazer a carga de dados para tensores para processamento posterior.\n",
        "\n",
        "Para ilustrar essa operação, vamos usar um conjunto de dados (*dataset*) bem simples denominado [Linnerud](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html). Esse conjunto de dados tem apenas 20 exemplos. Cada exemplo é representado por 3 variáveis ​​independentes e 3 alvos. A descrição do conjunto de dados Linnerud é a seguinte: \n",
        "\n",
        "> “O conjunto de dados Linnerud pode ser usado para ajustar modelos de regressão de múltiplas saídas. É composto por três variáveis sobre atividade física (matriz de dados, $X$) e três variáveis que medem características ​​fisiológicas (matriz alvo, $y$) coletados de vinte homens de meia-idade em um clube de fitness.\n",
        "\n",
        "- variáveis relacionadas ao perfil de atividade física do indivíduo ($X$)- :  \"puxar ferro\" (Chins), abdominais (Situps) e saltos (Jumps).\n",
        "\n",
        "- variáveis relacionadas ao perfil fisiológico do indivíduo ($y$) - Peso (Weight), Cintura (Weist) e Pulso (Pulse).\n",
        "\n",
        "Mais informações sobre esse conjunto de dados podem ser encontradas nos links abaixo:\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html\n",
        "\n",
        "- https://scikit-learn.org/stable/datasets/toy_dataset.html#linnerrud-dataset\n",
        "\n",
        "- https://ai.plainenglish.io/an-exploration-into-sklearns-linnerrud-multioutput-dataset-4e0ad110c728"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA4-j7UDjsRh"
      },
      "source": [
        "Dimensões da matriz de dados e da matriz alvo:\n",
        "- $X \\in \\mathbb{R}^{20 \\times 3}$: matriz de dados (*data matrix*)\n",
        "- $y \\in \\mathbb{R}^{20 \\times 3}$: matriz alvo (*target matrix*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmV0WJ07iF1i"
      },
      "source": [
        "from sklearn.datasets import load_linnerud\n",
        "import torch\n",
        "\n",
        "X_, y_ = load_linnerud(return_X_y = True)\n",
        "\n",
        "X = torch.from_numpy(X_) # utlizando o numpy para compactando em tensores\n",
        "y = torch.from_numpy(y_)\n",
        "\n",
        "X, y = X.float(), y.float()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEhZkCvoUjdW",
        "outputId": "e6effb5d-5aba-4c75-f187-d38c6d3ba7ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uv905UtiWwY"
      },
      "source": [
        "## TensorDataset e DataLoader\n",
        "\n",
        "Criaremos um objeto `TensorDataset`, que propicia acesso aos exemplos de um conjunto de dados representados como tensores. O objeto `TensorDataset` fornece uma API padrão para trabalhar com muitos tipos diferentes de conjuntos de dados em PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeFmU0mNiXK_"
      },
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZSHqDYfiaFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccd7901-9d54-4d83-c83a-b2020fc15264"
      },
      "source": [
        "# Define dataset\n",
        "train_ds = TensorDataset(X, y) #particionando os dados X e y\n",
        "train_ds[0:5] # insepcionando o objeto "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  5., 162.,  60.],\n",
              "         [  2., 110.,  60.],\n",
              "         [ 12., 101., 101.],\n",
              "         [ 12., 105.,  37.],\n",
              "         [ 13., 155.,  58.]]), tensor([[191.,  36.,  50.],\n",
              "         [189.,  37.,  52.],\n",
              "         [193.,  38.,  58.],\n",
              "         [162.,  35.,  62.],\n",
              "         [189.,  35.,  46.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gwBcyE7jSoW"
      },
      "source": [
        "O `TensorDataset` permite fazer acesso a uma seção dos dados de treinamento usando a notação de indexação de array (`[0:5]` no código acima). Quando usamos essa indexação, obtemos como resultado uma tupla com dois elementos. O primeiro elemento contém as variáveis independentes para as linhas selecionadas e o segundo contém o alvos correspondentes.\n",
        "\n",
        "Também criaremos um objeto `DataLoader`, que pode dividir os exemplos em um conjunto de dados em vários **lotes** (*batchs*) de um tamanho predefinido. Esse objeto também fornece outros funções utilitárias, como embaralhamento e amostragem aleatória dos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S8HhPeejqGc"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALJthJxdjnoU"
      },
      "source": [
        "# Define o objeto DataLoader\n",
        "batch_size = 6 # definindo o tamanho lotes do dataset\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True) # é uma boa pratica fazer o shuffle dos dados"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm18KSxxj5R2"
      },
      "source": [
        "É comum usar um objeto `DataLoader` em um laço de repetição para percorrer os exemplos de um conjunto de dados. Em cada iteração do laço de repetição, um lote (*batch*) de exemplos é produzido. O tamanho do lote é definido na criação do objeto `DataLoader`. Veja o código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNZn5ytnj4hH"
      },
      "source": [
        "for i, (xb, yb) in enumerate(train_dl):\n",
        "    print('Batch #%d:' % i)\n",
        "    print(xb)\n",
        "    print(yb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucCCr4qlkIt2"
      },
      "source": [
        "Em cada iteração, o objeto `DataLoader` retorna um **lote** de dados com o tamanho de lote previamente fornecido (argumento `batch_size`). Se `shuffle` tiver sido definido como `True`, esse objeto também embaralha os dados do conjunto antes de criar lotes. \n",
        "\n",
        "O embaralhamento dos exemplos ajuda no processo de convergência do algoritmo de otimização, levando a uma redução mais rápida da função de custo. Veja essa [discussão](https://datascience.stackexchange.com/questions/24511/why-should-the-data-be-shuffled-for-machine-learning-tasks) para mais detalhes sobre isso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO0QRJZ1keA6"
      },
      "source": [
        "## Construção do modelo\n",
        "\n",
        "Vamos construir um modelo de rede neural bem simples, com apenas a camada de entrada (correspondente aos próprios dados de treinamento) e a camada de saída (i.e., sem camadas intermediárias).\n",
        "\n",
        "Em vez de implementar a parte de código para inicializar os pesos e viéses, podemos definir o modelo usando a classe `nn.Linear` do PyTorch, que faz isso automaticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEuzpqLjkmF0",
        "outputId": "5a767d60-6d1a-4e28-907e-f4647d379527"
      },
      "source": [
        "# Define o modelo\n",
        "model = torch.nn.Linear(3, 3) #Encapsulamento da função de ativação\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2920,  0.0425, -0.0058],\n",
            "        [-0.1422, -0.4074,  0.3152],\n",
            "        [ 0.5000, -0.1893,  0.5334]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.4418,  0.5371, -0.4734], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe que o objeto `nn.Linear` encapsula os parâmetros do modelo (i.e., a matriz de pesos $W$ e o vetor de viéses $b$). Esse mesmo objeto já implementa a operação de multiplicação de dos pesos pelos exemplos de entrada e a consecutiva adição do viés (*bias*). De fato, dada uma matriz de dados $X$ (com cada exemplo armazenado em uma de suas linhas), esse objeto Linear computa a expressão matemática abaixo:\n",
        "\n",
        "$$\n",
        "W \\times X^T + b\n",
        "$$\n",
        "\n",
        "Veja o código abaixo."
      ],
      "metadata": {
        "id": "zXXRFGJyuHfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(model(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKxQPoARuDem",
        "outputId": "555393a8-40ce-4896-95b2-75175d6be66b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5., 162.,  60.],\n",
            "        [  2., 110.,  60.],\n",
            "        [ 12., 101., 101.],\n",
            "        [ 12., 105.,  37.],\n",
            "        [ 13., 155.,  58.],\n",
            "        [  4., 101.,  42.],\n",
            "        [  8., 101.,  38.],\n",
            "        [  6., 125.,  40.],\n",
            "        [ 15., 200.,  40.],\n",
            "        [ 17., 251., 250.],\n",
            "        [ 17., 120.,  38.],\n",
            "        [ 13., 210., 115.],\n",
            "        [ 14., 215., 105.],\n",
            "        [  1.,  50.,  50.],\n",
            "        [  6.,  70.,  31.],\n",
            "        [ 12., 210., 120.],\n",
            "        [  4.,  60.,  25.],\n",
            "        [ 11., 230.,  80.],\n",
            "        [ 15., 225.,  73.],\n",
            "        [  2., 110.,  43.]])\n",
            "tensor([[  5.5171, -47.2586,   3.3677],\n",
            "        [  4.1839, -25.6479,  11.7104],\n",
            "        [  0.6435, -10.4805,  40.2838],\n",
            "        [  1.1841, -32.2827,   5.3881],\n",
            "        [  2.8949, -46.1751,   7.6257],\n",
            "        [  3.3216, -27.9394,   4.8124],\n",
            "        [  2.1766, -29.7691,   4.6787],\n",
            "        [  3.7688, -38.6315,   0.2028],\n",
            "        [  4.3270, -70.4654,  -9.4935],\n",
            "        [  4.6934, -25.3349,  93.8701],\n",
            "        [  0.3554, -38.7894,   5.5822],\n",
            "        [  4.9015, -50.6150,  27.6198],\n",
            "        [  4.8799, -55.9461,  21.8392],\n",
            "        [  1.9845,  -4.2145,  17.2332],\n",
            "        [  1.4841, -19.0621,   5.8126],\n",
            "        [  5.1646, -48.8968,  29.7869],\n",
            "        [  1.6781, -16.5950,   3.5050],\n",
            "        [  6.5381, -69.5102,   4.1647],\n",
            "        [  5.1981, -70.2485,   3.3771],\n",
            "        [  4.2823, -31.0063,   2.6423]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao analisar o resultado acima, você pode ver uma grande diferença entre as previsões do modelo e os valores verdadeiros porque inicializamos nosso modelo com pesos e vieses aleatórios. Obviamente, não podemos esperar que um modelo cujos parâmetros foram iniciados aleatoriamente funcione adequadamente."
      ],
      "metadata": {
        "id": "AZOCiqkNfSui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função de custo\n",
        "\n",
        "Para que possamos melhorar nosso modelo, precisamos de uma forma objetiva de avaliar o desempenho preditivo dele. Podemos comparar as previsões do modelo com os alvos reais usando o seguinte método:\n",
        "\n",
        "- Calcular a diferença entre as duas matrizes (`y_pred` e `y`).\n",
        "- Elevar ao quadrado cada elemento da matriz de diferença para remover valores negativos.\n",
        "- Calcular a média dos elementos na matriz resultante.\n",
        "\n",
        "O resultado é um único número, conhecido como erro quadrático médio (MSE, *mean squared error*). Matematicamente, os passos acima se traduzem nas seguintes expressões, onde $n$ é a quantidade de variáveis alvo:\n",
        "\n",
        "\\begin{align}\n",
        "D &= (y - y_{\\text{pred}}) \\\\\n",
        "S &= D \\odot D \\\\\n",
        "\\operatorname{MSE} &= \\frac{1}{n} \\sum_{1 \\leq i,j \\leq n} S_{ij} \n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "AJvdBa5h561P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka7S-o4VlMKF"
      },
      "source": [
        "O pacote `nn.Functional` fornece a implementação de muitas funções de custo úteis e vários outros utilitários. Em particular, vamos usar a implementação da função de custo MSE fornecida por esse pacote."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs1V35YvlMri"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Define loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alC2-qiulXVd"
      },
      "source": [
        "Vamos computar o valor inicial da função de custo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXcqm7JSlVX_",
        "outputId": "18f9ce9f-51e0-4f7b-8605-09125bff464e"
      },
      "source": [
        "loss = loss_fn(model(X), y)\n",
        "print(loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(13078.7627, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYkIy4qkdiM6",
        "outputId": "ca7dcb20-c781-41cc-e07c-84de9c3188fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114.36241819458218"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3viNOf7Clr5"
      },
      "source": [
        "Podemos interpretar o valor produzido acima da seguinte forma: \n",
        "\n",
        "> Em média, cada previsão feita pelo modelo difere do alvo (valor verdadeiro) pela raiz quadrada do valor da função de custo. \n",
        "\n",
        "Objetivamente, esse resultado é muito ruim, considerando que os números que estamos tentando prever estão na faixa de 30-250. O resultado é chamado de perda porque indica o quão ruim o modelo é em prever as variáveis alvo. Representa a perda de informações no modelo: quanto menor a perda, melhor é o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HrCwSCLDEgU"
      },
      "source": [
        "## Cálculo dos gradientes\n",
        "\n",
        "Com PyTorch, podemos calcular automaticamente os gradientes (i.e., as derivadas parciais da função de custo com relação a cada um dos parâmetros do modelo). Isso porque eles foram definidos com `requires_grad` igual a `True`. Esse cálculo é realizado ao invocar a função `backward`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2fG4Gj9C6iI"
      },
      "source": [
        "# Computa os gradientes (diferenciação automática; autograd)\n",
        "loss.backward()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ead3HsIrDYcx"
      },
      "source": [
        "Os gradientes são armazenados na propriedade `.grad` dos respectivos tensores. Observe que as derivadas parciais da função de custo com relação a cada elemento da matriz de pesos $W$ podem ser organizados em outra matriz com as mesmas dimensões. O mesmo pode ser feito com relação ao vetor $b$. Se denotarmos por $J$ a função de custo e por $dW$ e $db$ essas novas matrizes, temos:\n",
        "\n",
        "$$\n",
        "dW = \n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial J}{\\partial w_{11}} & \\frac{\\partial J}{\\partial w_{12}} & \\frac{\\partial J}{\\partial w_{13}}\\\\\n",
        "\\frac{\\partial J}{\\partial w_{21}} & \\frac{\\partial J}{\\partial w_{22}} & \\frac{\\partial J}{\\partial w_{23}}\\\\\n",
        "\\frac{\\partial J}{\\partial w_{31}} & \\frac{\\partial J}{\\partial w_{32}} & \\frac{\\partial J}{\\partial w_{33}}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "db = \n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial J}{\\partial b_{1}} \\\\\n",
        "\\frac{\\partial J}{\\partial b_{2}} \\\\\n",
        "\\frac{\\partial J}{\\partial b_{3}}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Os matemáticos chamam cada uma das matrizes acima de [Jacobiana](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRDP7IWgD1S8"
      },
      "source": [
        "A função de custo MSE é uma função quadrática dos pesos e vieses, e nosso objetivo é encontrar o conjunto de parâmetros onde a função de custo é mínima. Se traçarmos um gráfico da função de custo com qualquer parâmetro individual (peso ou viés), ele se parecerá com a figura mostrada no link a seguir: https://www.geogebra.org/m/j8jqxyrs.\n",
        "\n",
        "Um informação importante é que cada derivada parcial contida na Jacobiana $dW$ indica a taxa de variação da função de custo em uma direção específica, ou seja, a inclinação dessa função.\n",
        "\n",
        "Se um elemento de $dW$ for **positivo**, então:\n",
        "- **aumentar** ligeiramente o valor do parâmetro correspondente **aumenta** o valor da função de custo;\n",
        "- **diminuir** ligeiramente o valor do peso correspondente  **diminui** o valor da função de custo.\n",
        "\n",
        "Se um elemento de $dW$ for **negativo**, então:\n",
        "- **aumentar** ligeiramente o valor do peso correspondente **diminui** o valor da função de custo;\n",
        "- **diminuir** ligeiramente o valor do peso correspondente **aumenta** o valor da função de custo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz3cUmjPEoEq"
      },
      "source": [
        "O aumento ou diminuição na função $J$ causado pela mudança no valor um elemento em $W$ é proporcional a esse valor. Essa observação forma a base do algoritmo de otimização de **gradiente descendente** que usaremos para melhorar nosso modelo.\n",
        "\n",
        "> Podemos subtrair de cada elemento de $W$ uma pequena quantidade proporcional à derivada de $J$ com relação a esse elemento para reduzir ligeiramente o custo.\n",
        "\n",
        "Por exemplo, para atualizar o peso $w_{11}$, a seguinte expressão deve ser usada:\n",
        "\n",
        "$$\n",
        "w_{11} \\leftarrow w_{11} - \\alpha \\times \\frac{\\partial J}{\\partial w_{11}}\n",
        "$$\n",
        "\n",
        "A mesma explicação dada acima no contexto da matriz de pesos ($W$) pode ser dada no contexto do vetor de viéses ($b$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKuvVrAhldCg"
      },
      "source": [
        "## Otimizador\n",
        "\n",
        "Vamos usar o otimizador `optim.SGD`. SGD é a abreviatura de *sthocastic gradient descent* (descida do gradiente estocástica). O termo *estocástico* indica que as amostras são selecionadas em lotes aleatórios, em vez de como um único grupo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V_GKVIcmG4i"
      },
      "source": [
        "# Define o otimizadora ser usado (Sthocastic Gradient Descent)\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5) # lr = learn rate, o alfa da equação acima"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRjzSf_1mHmL"
      },
      "source": [
        "Observe que `model.parameters()` é passado como um argumento para `optim.SGD` para que o otimizador saiba quais matrizes devem ser modificadas durante a etapa de atualização. Além disso, podemos especificar uma taxa de aprendizado que controla a quantidade pela qual os parâmetros são modificados."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `model.parameters()` encapsula uma estrutura de dados que armazena todos os tensores (matrizes ou vetores) de parâmetros do modelo. Veja o código a seguir."
      ],
      "metadata": {
        "id": "vmWA0cHfxqkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in model.parameters():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq4yFFJzxhhN",
        "outputId": "bbfe75fc-9859-450c-bd25-ddfc97918ac0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2920,  0.0425, -0.0058],\n",
            "        [-0.1422, -0.4074,  0.3152],\n",
            "        [ 0.5000, -0.1893,  0.5334]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.4418,  0.5371, -0.4734], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tIMvv9Omh8i"
      },
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "Agora estamos prontos para treinar o modelo. Seguiremos o mesmo processo para implementar a descida do gradiente:\n",
        "\n",
        "1. Gerar previsões passando para o modelo alguns exemplos de treinamento;\n",
        "2. Com as previsões geradas, calcular o valor da função de custo;\n",
        "3. Calcular gradientes (derivadas parciais) com relação aos parâmetros (pesos e viéses);\n",
        "4. Ajustar os parâmetros subtraindo deles uma pequena quantidade proporcional ao gradiente;\n",
        "5. Redefinir os gradientes para zero.\n",
        "\n",
        "Na terminologia de algoritmos de aprendizado de máquina baseados em gradiente, toda vez que o algoritmo executa os passos acima, dizemos que ele executou uma **iteração de treinamento**, ou simplesmente **iteração**.\n",
        "\n",
        "Na implementação abaixo, passamos *lotes de dados* para o modelo (veja o passo 1 acima), em vez de passar todos os exemplos de treinamento de uma única vez. Vamos definir uma função auxiliar denominada `fit` que treina o modelo por um determinado número de **épocas**. Cada época corresponde a várias iterações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjjo8i7amjzO"
      },
      "source": [
        "# Utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    \n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb, yb in train_dl:\n",
        "            \n",
        "            # 1. Generate predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # 3. Compute gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reset the gradients to zero\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MpBJ-JHnQCG"
      },
      "source": [
        "Algumas coisas a serem observadas no código acima:\n",
        "\n",
        "- Usamos o objeto `DataLoader` definido anteriormente para obter lotes de dados para cada iteração.\n",
        "\n",
        "- Em vez de implementar a atualização dos parâmetros (pesos e viéses), usamos a função `opt.step` para realizar essa atualização e [opt.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html) para redefinir os gradientes para zero.\n",
        "\n",
        "- Também adicionamos um trecho de código para registrar o valor da função de custo (computada em cada lote de dados) para cada 10ª época. Esse trecho nos permitirá rastrear o progresso do treinamento. `loss.item` retorna o valor real armazenado no tensor zero-dimensional da função de custo.\n",
        "\n",
        "Vamos treinar o modelo por 100 épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkDIAj98nRBR",
        "outputId": "d612ff2e-66fa-45b6-8a4d-38c2cc506c57"
      },
      "source": [
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 2002.7650\n",
            "Epoch [20/100], Loss: 2403.7451\n",
            "Epoch [30/100], Loss: 512.5737\n",
            "Epoch [40/100], Loss: 4071.0598\n",
            "Epoch [50/100], Loss: 1181.4362\n",
            "Epoch [60/100], Loss: 2388.3684\n",
            "Epoch [70/100], Loss: 7191.7720\n",
            "Epoch [80/100], Loss: 411.2676\n",
            "Epoch [90/100], Loss: 1843.1056\n",
            "Epoch [100/100], Loss: 2739.9717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhHHcKBZoV23"
      },
      "source": [
        "Vamos agora gerar previsões usando o modelo atual e verificar se elas estão próximas dos alvos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBodLw55oaWo",
        "outputId": "c6d4f779-c976-46d9-f456-b889f44248c5"
      },
      "source": [
        "y_pred = model(X)\n",
        "y_pred"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[171.0631,  34.2474,  55.3488],\n",
              "        [114.6619,  23.3948,  35.4771],\n",
              "        [107.9401,  21.9512,  34.8847],\n",
              "        [116.3070,  22.8968,  40.6180],\n",
              "        [168.1547,  33.2001,  57.2985],\n",
              "        [107.4335,  21.6736,  34.6008],\n",
              "        [109.8608,  21.8763,  37.0081],\n",
              "        [133.9281,  26.7163,  44.2364],\n",
              "        [217.8085,  42.5971,  75.3940],\n",
              "        [258.9863,  52.7946,  80.1792],\n",
              "        [134.7523,  26.2271,  48.4914],\n",
              "        [222.3912,  44.4154,  72.7671],\n",
              "        [228.8489,  45.5127,  75.7342],\n",
              "        [ 51.5665,  11.0116,  14.5393],\n",
              "        [ 76.5767,  15.4094,  25.5219],\n",
              "        [221.5248,  44.3571,  71.8947],\n",
              "        [ 65.3484,  13.2644,  21.3459],\n",
              "        [244.6461,  48.5025,  81.0921],\n",
              "        [242.0013,  47.6814,  81.9457],\n",
              "        [115.7651,  23.4272,  36.6267]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare o tensor acima com o tensor de alvo exibido abaixo."
      ],
      "metadata": {
        "id": "KatLYM7u9Y7X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OYed8LWofcp",
        "outputId": "28df713e-65cf-4cf5-c300-8c1d555ca65b"
      },
      "source": [
        "y"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[191.,  36.,  50.],\n",
              "        [189.,  37.,  52.],\n",
              "        [193.,  38.,  58.],\n",
              "        [162.,  35.,  62.],\n",
              "        [189.,  35.,  46.],\n",
              "        [182.,  36.,  56.],\n",
              "        [211.,  38.,  56.],\n",
              "        [167.,  34.,  60.],\n",
              "        [176.,  31.,  74.],\n",
              "        [154.,  33.,  56.],\n",
              "        [169.,  34.,  50.],\n",
              "        [166.,  33.,  52.],\n",
              "        [154.,  34.,  64.],\n",
              "        [247.,  46.,  50.],\n",
              "        [193.,  36.,  46.],\n",
              "        [202.,  37.,  62.],\n",
              "        [176.,  37.,  54.],\n",
              "        [157.,  32.,  52.],\n",
              "        [156.,  33.,  54.],\n",
              "        [138.,  33.,  68.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PA6mG8SonTQ"
      },
      "source": [
        "De fato, as previsões estão bem próximas dos alvos. Treinamos um modelo razoavelmente bom para prever o perfil fisiológico de um indivíduo, dado que sabemos seu perfil de realização de exercícios físicos.\n",
        "\n",
        "O código abaixo exemplifica de que forma o modelo pode ser usado para fazer predições sobre novos indivíduos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPErkTiVo4EH",
        "outputId": "636863c0-4c10-486a-ef86-083acda5237c"
      },
      "source": [
        "model(torch.tensor([[6., 152., 59.]])) # inferência"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[161.1362,  32.2392,  52.4374]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}