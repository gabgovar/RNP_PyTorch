{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-processamento.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabgovar/RNP_PyTorch/blob/main/Pre_processamento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Créditos\n",
        "\n",
        "O conteúdo deste notebook usa material das seguintes fontes:\n",
        "\n",
        "- [Deep Learning Wizard](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_logistic_regression/)\n",
        "\n",
        "- [Deep Learning with PyTorch: Zero to GANs](https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans)\n",
        "\n",
        "- [Machine Learning Glossary](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)"
      ],
      "metadata": {
        "id": "0VTuDuUrq3fl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMNlhyt2h-AH"
      },
      "source": [
        "# Regressão Linear\n",
        "\n",
        "Nesta seção, vamos resolver um problema de regressão linear tentando usar classes fornecidas pelo PyTorch para manipulação de conjuntos de dados. Vamos perceber que o PyTorch fornece a implementação de diversas partes do *pipeline* de treinamento de uma rede neural artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT8PKx981tac"
      },
      "source": [
        "## Armazenamento de dados em tensores\n",
        "\n",
        "Uma operação bastante comum é fazer a carga de dados para tensores para processamento posterior.\n",
        "\n",
        "Para ilustrar essa operação, vamos usar um conjunto de dados (*dataset*) bem simples denominado [Linnerud](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html). Esse conjunto de dados tem apenas 20 exemplos. Cada exemplo é representado por 3 variáveis ​​independentes e 3 alvos. A descrição do conjunto de dados Linnerud é a seguinte: \n",
        "\n",
        "> “O conjunto de dados Linnerud pode ser usado para ajustar modelos de regressão de múltiplas saídas. É composto por três variáveis sobre atividade física (matriz de dados, $X$) e três variáveis que medem características ​​fisiológicas (matriz alvo, $y$) coletados de vinte homens de meia-idade em um clube de fitness.\n",
        "\n",
        "- variáveis relacionadas ao perfil de atividade física do indivíduo ($X$)- :  \"puxar ferro\" (Chins), abdominais (Situps) e saltos (Jumps).\n",
        "\n",
        "- variáveis relacionadas ao perfil fisiológico do indivíduo ($y$) - Peso (Weight), Cintura (Weist) e Pulso (Pulse).\n",
        "\n",
        "Mais informações sobre esse conjunto de dados podem ser encontradas nos links abaixo:\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html\n",
        "\n",
        "- https://scikit-learn.org/stable/datasets/toy_dataset.html#linnerrud-dataset\n",
        "\n",
        "- https://ai.plainenglish.io/an-exploration-into-sklearns-linnerrud-multioutput-dataset-4e0ad110c728"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA4-j7UDjsRh"
      },
      "source": [
        "Dimensões da matriz de dados e da matriz alvo:\n",
        "- $X \\in \\mathbb{R}^{20 \\times 3}$: matriz de dados (*data matrix*)\n",
        "- $y \\in \\mathbb{R}^{20 \\times 3}$: matriz alvo (*target matrix*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmV0WJ07iF1i"
      },
      "source": [
        "from sklearn.datasets import load_linnerud\n",
        "import torch\n",
        "\n",
        "X_, y_ = load_linnerud(return_X_y = True)\n",
        "\n",
        "X = torch.from_numpy(X_) # utlizando o numpy para compactando em tensores\n",
        "y = torch.from_numpy(y_)\n",
        "\n",
        "X, y = X.float(), y.float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEhZkCvoUjdW",
        "outputId": "f1ee3343-0321-4414-eac6-ffdc18907b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uv905UtiWwY"
      },
      "source": [
        "## TensorDataset e DataLoader\n",
        "\n",
        "Criaremos um objeto `TensorDataset`, que propicia acesso aos exemplos de um conjunto de dados representados como tensores. O objeto `TensorDataset` fornece uma API padrão para trabalhar com muitos tipos diferentes de conjuntos de dados em PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeFmU0mNiXK_"
      },
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZSHqDYfiaFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0541d979-d5cf-4936-fd0c-606a805c6ede"
      },
      "source": [
        "# Define dataset\n",
        "train_ds = TensorDataset(X, y) #particionando os dados X e y\n",
        "train_ds[0:5] # insepcionando o objeto "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  5., 162.,  60.],\n",
              "         [  2., 110.,  60.],\n",
              "         [ 12., 101., 101.],\n",
              "         [ 12., 105.,  37.],\n",
              "         [ 13., 155.,  58.]]), tensor([[191.,  36.,  50.],\n",
              "         [189.,  37.,  52.],\n",
              "         [193.,  38.,  58.],\n",
              "         [162.,  35.,  62.],\n",
              "         [189.,  35.,  46.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gwBcyE7jSoW"
      },
      "source": [
        "O `TensorDataset` permite fazer acesso a uma seção dos dados de treinamento usando a notação de indexação de array (`[0:5]` no código acima). Quando usamos essa indexação, obtemos como resultado uma tupla com dois elementos. O primeiro elemento contém as variáveis independentes para as linhas selecionadas e o segundo contém o alvos correspondentes.\n",
        "\n",
        "Também criaremos um objeto `DataLoader`, que pode dividir os exemplos em um conjunto de dados em vários **lotes** (*batchs*) de um tamanho predefinido. Esse objeto também fornece outros funções utilitárias, como embaralhamento e amostragem aleatória dos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S8HhPeejqGc"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALJthJxdjnoU"
      },
      "source": [
        "# Define o objeto DataLoader\n",
        "batch_size = 6 # definindo o tamanho lotes do dataset\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True) # é uma boa pratica fazer o shuffle dos dados"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm18KSxxj5R2"
      },
      "source": [
        "É comum usar um objeto `DataLoader` em um laço de repetição para percorrer os exemplos de um conjunto de dados. Em cada iteração do laço de repetição, um lote (*batch*) de exemplos é produzido. O tamanho do lote é definido na criação do objeto `DataLoader`. Veja o código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNZn5ytnj4hH",
        "outputId": "667cb6ab-c9c8-48e7-ea2d-63fba93a7c9a"
      },
      "source": [
        "for i, (xb, yb) in enumerate(train_dl):\n",
        "    print('Batch #%d:' % i)\n",
        "    print(xb)\n",
        "    print(yb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch #0:\n",
            "tensor([[  2., 110.,  60.],\n",
            "        [ 15., 225.,  73.],\n",
            "        [  8., 101.,  38.],\n",
            "        [ 12., 105.,  37.],\n",
            "        [ 12., 101., 101.],\n",
            "        [  1.,  50.,  50.]])\n",
            "tensor([[189.,  37.,  52.],\n",
            "        [156.,  33.,  54.],\n",
            "        [211.,  38.,  56.],\n",
            "        [162.,  35.,  62.],\n",
            "        [193.,  38.,  58.],\n",
            "        [247.,  46.,  50.]])\n",
            "Batch #1:\n",
            "tensor([[ 17., 120.,  38.],\n",
            "        [ 14., 215., 105.],\n",
            "        [  4.,  60.,  25.],\n",
            "        [ 17., 251., 250.],\n",
            "        [ 11., 230.,  80.],\n",
            "        [ 13., 155.,  58.]])\n",
            "tensor([[169.,  34.,  50.],\n",
            "        [154.,  34.,  64.],\n",
            "        [176.,  37.,  54.],\n",
            "        [154.,  33.,  56.],\n",
            "        [157.,  32.,  52.],\n",
            "        [189.,  35.,  46.]])\n",
            "Batch #2:\n",
            "tensor([[  4., 101.,  42.],\n",
            "        [  6.,  70.,  31.],\n",
            "        [ 15., 200.,  40.],\n",
            "        [ 13., 210., 115.],\n",
            "        [  2., 110.,  43.],\n",
            "        [  6., 125.,  40.]])\n",
            "tensor([[182.,  36.,  56.],\n",
            "        [193.,  36.,  46.],\n",
            "        [176.,  31.,  74.],\n",
            "        [166.,  33.,  52.],\n",
            "        [138.,  33.,  68.],\n",
            "        [167.,  34.,  60.]])\n",
            "Batch #3:\n",
            "tensor([[  5., 162.,  60.],\n",
            "        [ 12., 210., 120.]])\n",
            "tensor([[191.,  36.,  50.],\n",
            "        [202.,  37.,  62.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucCCr4qlkIt2"
      },
      "source": [
        "Em cada iteração, o objeto `DataLoader` retorna um **lote** de dados com o tamanho de lote previamente fornecido (argumento `batch_size`). Se `shuffle` tiver sido definido como `True`, esse objeto também embaralha os dados do conjunto antes de criar lotes. \n",
        "\n",
        "O embaralhamento dos exemplos ajuda no processo de convergência do algoritmo de otimização, levando a uma redução mais rápida da função de custo. Veja essa [discussão](https://datascience.stackexchange.com/questions/24511/why-should-the-data-be-shuffled-for-machine-learning-tasks) para mais detalhes sobre isso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO0QRJZ1keA6"
      },
      "source": [
        "## Construção do modelo\n",
        "\n",
        "Vamos construir um modelo de rede neural bem simples, com apenas a camada de entrada (correspondente aos próprios dados de treinamento) e a camada de saída (i.e., sem camadas intermediárias).\n",
        "\n",
        "Em vez de implementar a parte de código para inicializar os pesos e viéses, podemos definir o modelo usando a classe `nn.Linear` do PyTorch, que faz isso automaticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEuzpqLjkmF0",
        "outputId": "877c3dfd-99fd-418e-c570-fe859d42b32e"
      },
      "source": [
        "# Define o modelo\n",
        "model = torch.nn.Linear(3, 3) #Encapsulamento da função de ativação\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.4223,  0.0428, -0.5370],\n",
            "        [ 0.0909, -0.5301,  0.4793],\n",
            "        [-0.1084, -0.2877,  0.3270]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0955,  0.4908, -0.0179], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe que o objeto `nn.Linear` encapsula os parâmetros do modelo (i.e., a matriz de pesos $W$ e o vetor de viéses $b$). Esse mesmo objeto já implementa a operação de multiplicação de dos pesos pelos exemplos de entrada e a consecutiva adição do viés (*bias*). De fato, dada uma matriz de dados $X$ (com cada exemplo armazenado em uma de suas linhas), esse objeto Linear computa a expressão matemática abaixo:\n",
        "\n",
        "$$\n",
        "W \\times X^T + b\n",
        "$$\n",
        "\n",
        "Veja o código abaixo."
      ],
      "metadata": {
        "id": "zXXRFGJyuHfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(model(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKxQPoARuDem",
        "outputId": "0edb6835-93e6-4a7e-a41f-71836b736cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  5., 162.,  60.],\n",
            "        [  2., 110.,  60.],\n",
            "        [ 12., 101., 101.],\n",
            "        [ 12., 105.,  37.],\n",
            "        [ 13., 155.,  58.],\n",
            "        [  4., 101.,  42.],\n",
            "        [  8., 101.,  38.],\n",
            "        [  6., 125.,  40.],\n",
            "        [ 15., 200.,  40.],\n",
            "        [ 17., 251., 250.],\n",
            "        [ 17., 120.,  38.],\n",
            "        [ 13., 210., 115.],\n",
            "        [ 14., 215., 105.],\n",
            "        [  1.,  50.,  50.],\n",
            "        [  6.,  70.,  31.],\n",
            "        [ 12., 210., 120.],\n",
            "        [  4.,  60.,  25.],\n",
            "        [ 11., 230.,  80.],\n",
            "        [ 15., 225.,  73.],\n",
            "        [  2., 110.,  43.]])\n",
            "tensor([[ -27.4840,  -56.1799,  -27.5442],\n",
            "        [ -28.4449,  -28.8853,  -12.2588],\n",
            "        [ -55.0687,   -3.5541,    2.6549],\n",
            "        [ -20.5322,  -36.3492,  -19.4264],\n",
            "        [ -30.0885,  -52.7002,  -27.0517],\n",
            "        [ -20.0099,  -32.5595,  -15.7731],\n",
            "        [ -19.5513,  -34.1130,  -17.5149],\n",
            "        [ -18.7524,  -46.0596,  -23.5487],\n",
            "        [ -19.3400,  -85.0019,  -46.1016],\n",
            "        [-130.7605,  -11.2063,    7.6875],\n",
            "        [ -22.5381,  -43.3675,  -23.9569],\n",
            "        [ -58.3387,  -54.5384,  -24.2337],\n",
            "        [ -53.1772,  -61.8910,  -29.0510],\n",
            "        [ -25.2235,   -1.9608,    1.8409],\n",
            "        [ -16.2761,  -21.2155,  -10.6688],\n",
            "        [ -60.6012,  -52.2328,  -22.4901],\n",
            "        [ -12.6381,  -18.9717,   -9.5373],\n",
            "        [ -37.8438,  -82.0981,  -41.2172],\n",
            "        [ -35.9886,  -82.4388,  -42.5017],\n",
            "        [ -19.3166,  -37.0333,  -17.8185]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao analisar o resultado acima, você pode ver uma grande diferença entre as previsões do modelo e os valores verdadeiros porque inicializamos nosso modelo com pesos e vieses aleatórios. Obviamente, não podemos esperar que um modelo cujos parâmetros foram iniciados aleatoriamente funcione adequadamente."
      ],
      "metadata": {
        "id": "AZOCiqkNfSui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função de custo\n",
        "\n",
        "Para que possamos melhorar nosso modelo, precisamos de uma forma objetiva de avaliar o desempenho preditivo dele. Podemos comparar as previsões do modelo com os alvos reais usando o seguinte método:\n",
        "\n",
        "- Calcular a diferença entre as duas matrizes (`y_pred` e `y`).\n",
        "- Elevar ao quadrado cada elemento da matriz de diferença para remover valores negativos.\n",
        "- Calcular a média dos elementos na matriz resultante.\n",
        "\n",
        "O resultado é um único número, conhecido como erro quadrático médio (MSE, *mean squared error*). Matematicamente, os passos acima se traduzem nas seguintes expressões, onde $n$ é a quantidade de variáveis alvo:\n",
        "\n",
        "\\begin{align}\n",
        "D &= (y - y_{\\text{pred}}) \\\\\n",
        "S &= D \\odot D \\\\\n",
        "\\operatorname{MSE} &= \\frac{1}{n} \\sum_{1 \\leq i,j \\leq n} S_{ij} \n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "AJvdBa5h561P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka7S-o4VlMKF"
      },
      "source": [
        "O pacote `nn.Functional` fornece a implementação de muitas funções de custo úteis e vários outros utilitários. Em particular, vamos usar a implementação da função de custo MSE fornecida por esse pacote."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs1V35YvlMri"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Define loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alC2-qiulXVd"
      },
      "source": [
        "Vamos computar o valor inicial da função de custo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXcqm7JSlVX_",
        "outputId": "4aae464e-875e-40fc-e04a-0740e41cda66"
      },
      "source": [
        "loss = loss_fn(model(X), y)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(19814.1680, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYkIy4qkdiM6",
        "outputId": "235f5a04-518a-4864-88dc-95727b05260d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140.76280747679766"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3viNOf7Clr5"
      },
      "source": [
        "Podemos interpretar o valor produzido acima da seguinte forma: \n",
        "\n",
        "> Em média, cada previsão feita pelo modelo difere do alvo (valor verdadeiro) pela raiz quadrada do valor da função de custo. \n",
        "\n",
        "Objetivamente, esse resultado é muito ruim, considerando que os números que estamos tentando prever estão na faixa de 30-250. O resultado é chamado de perda porque indica o quão ruim o modelo é em prever as variáveis alvo. Representa a perda de informações no modelo: quanto menor a perda, melhor é o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HrCwSCLDEgU"
      },
      "source": [
        "## Cálculo dos gradientes\n",
        "\n",
        "Com PyTorch, podemos calcular automaticamente os gradientes (i.e., as derivadas parciais da função de custo com relação a cada um dos parâmetros do modelo). Isso porque eles foram definidos com `requires_grad` igual a `True`. Esse cálculo é realizado ao invocar a função `backward`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2fG4Gj9C6iI"
      },
      "source": [
        "# Computa os gradientes (diferenciação automática; autograd)\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ead3HsIrDYcx"
      },
      "source": [
        "Os gradientes são armazenados na propriedade `.grad` dos respectivos tensores. Observe que as derivadas parciais da função de custo com relação a cada elemento da matriz de pesos $W$ podem ser organizados em outra matriz com as mesmas dimensões. O mesmo pode ser feito com relação ao vetor $b$. Se denotarmos por $J$ a função de custo e por $dW$ e $db$ essas novas matrizes, temos:\n",
        "\n",
        "$$\n",
        "dW = \n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial J}{\\partial w_{11}} & \\frac{\\partial J}{\\partial w_{12}} & \\frac{\\partial J}{\\partial w_{13}}\\\\\n",
        "\\frac{\\partial J}{\\partial w_{21}} & \\frac{\\partial J}{\\partial w_{22}} & \\frac{\\partial J}{\\partial w_{23}}\\\\\n",
        "\\frac{\\partial J}{\\partial w_{31}} & \\frac{\\partial J}{\\partial w_{32}} & \\frac{\\partial J}{\\partial w_{33}}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "db = \n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial J}{\\partial b_{1}} \\\\\n",
        "\\frac{\\partial J}{\\partial b_{2}} \\\\\n",
        "\\frac{\\partial J}{\\partial b_{3}}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Os matemáticos chamam cada uma das matrizes acima de [Jacobiana](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRDP7IWgD1S8"
      },
      "source": [
        "A função de custo MSE é uma função quadrática dos pesos e vieses, e nosso objetivo é encontrar o conjunto de parâmetros onde a função de custo é mínima. Se traçarmos um gráfico da função de custo com qualquer parâmetro individual (peso ou viés), ele se parecerá com a figura mostrada no link a seguir: https://www.geogebra.org/m/j8jqxyrs.\n",
        "\n",
        "Um informação importante é que cada derivada parcial contida na Jacobiana $dW$ indica a taxa de variação da função de custo em uma direção específica, ou seja, a inclinação dessa função.\n",
        "\n",
        "Se um elemento de $dW$ for **positivo**, então:\n",
        "- **aumentar** ligeiramente o valor do parâmetro correspondente **aumenta** o valor da função de custo;\n",
        "- **diminuir** ligeiramente o valor do peso correspondente  **diminui** o valor da função de custo.\n",
        "\n",
        "Se um elemento de $dW$ for **negativo**, então:\n",
        "- **aumentar** ligeiramente o valor do peso correspondente **diminui** o valor da função de custo;\n",
        "- **diminuir** ligeiramente o valor do peso correspondente **aumenta** o valor da função de custo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz3cUmjPEoEq"
      },
      "source": [
        "O aumento ou diminuição na função $J$ causado pela mudança no valor um elemento em $W$ é proporcional a esse valor. Essa observação forma a base do algoritmo de otimização de **gradiente descendente** que usaremos para melhorar nosso modelo.\n",
        "\n",
        "> Podemos subtrair de cada elemento de $W$ uma pequena quantidade proporcional à derivada de $J$ com relação a esse elemento para reduzir ligeiramente o custo.\n",
        "\n",
        "Por exemplo, para atualizar o peso $w_{11}$, a seguinte expressão deve ser usada:\n",
        "\n",
        "$$\n",
        "w_{11} \\leftarrow w_{11} - \\alpha \\times \\frac{\\partial J}{\\partial w_{11}}\n",
        "$$\n",
        "\n",
        "A mesma explicação dada acima no contexto da matriz de pesos ($W$) pode ser dada no contexto do vetor de viéses ($b$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKuvVrAhldCg"
      },
      "source": [
        "## Otimizador\n",
        "\n",
        "Vamos usar o otimizador `optim.SGD`. SGD é a abreviatura de *sthocastic gradient descent* (descida do gradiente estocástica). O termo *estocástico* indica que as amostras são selecionadas em lotes aleatórios, em vez de como um único grupo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V_GKVIcmG4i"
      },
      "source": [
        "# Define o otimizadora ser usado (Sthocastic Gradient Descent)\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRjzSf_1mHmL"
      },
      "source": [
        "Observe que `model.parameters()` é passado como um argumento para `optim.SGD` para que o otimizador saiba quais matrizes devem ser modificadas durante a etapa de atualização. Além disso, podemos especificar uma taxa de aprendizado que controla a quantidade pela qual os parâmetros são modificados."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `model.parameters()` encapsula uma estrutura de dados que armazena todos os tensores (matrizes ou vetores) de parâmetros do modelo. Veja o código a seguir."
      ],
      "metadata": {
        "id": "vmWA0cHfxqkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in model.parameters():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq4yFFJzxhhN",
        "outputId": "384e15d4-129a-46ba-e575-bd480103f0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.4223,  0.0428, -0.5370],\n",
            "        [ 0.0909, -0.5301,  0.4793],\n",
            "        [-0.1084, -0.2877,  0.3270]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0955,  0.4908, -0.0179], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tIMvv9Omh8i"
      },
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "Agora estamos prontos para treinar o modelo. Seguiremos o mesmo processo para implementar a descida do gradiente:\n",
        "\n",
        "1. Gerar previsões passando para o modelo alguns exemplos de treinamento;\n",
        "2. Com as previsões geradas, calcular o valor da função de custo;\n",
        "3. Calcular gradientes (derivadas parciais) com relação aos parâmetros (pesos e viéses);\n",
        "4. Ajustar os parâmetros subtraindo deles uma pequena quantidade proporcional ao gradiente;\n",
        "5. Redefinir os gradientes para zero.\n",
        "\n",
        "Na terminologia de algoritmos de aprendizado de máquina baseados em gradiente, toda vez que o algoritmo executa os passos acima, dizemos que ele executou uma **iteração de treinamento**, ou simplesmente **iteração**.\n",
        "\n",
        "Na implementação abaixo, passamos *lotes de dados* para o modelo (veja o passo 1 acima), em vez de passar todos os exemplos de treinamento de uma única vez. Vamos definir uma função auxiliar denominada `fit` que treina o modelo por um determinado número de **épocas**. Cada época corresponde a várias iterações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjjo8i7amjzO"
      },
      "source": [
        "# Utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    \n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb, yb in train_dl:\n",
        "            \n",
        "            # 1. Generate predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # 3. Compute gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reset the gradients to zero\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MpBJ-JHnQCG"
      },
      "source": [
        "Algumas coisas a serem observadas no código acima:\n",
        "\n",
        "- Usamos o objeto `DataLoader` definido anteriormente para obter lotes de dados para cada iteração.\n",
        "\n",
        "- Em vez de implementar a atualização dos parâmetros (pesos e viéses), usamos a função `opt.step` para realizar essa atualização e [opt.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html) para redefinir os gradientes para zero.\n",
        "\n",
        "- Também adicionamos um trecho de código para registrar o valor da função de custo (computada em cada lote de dados) para cada 10ª época. Esse trecho nos permitirá rastrear o progresso do treinamento. `loss.item` retorna o valor real armazenado no tensor zero-dimensional da função de custo.\n",
        "\n",
        "Vamos treinar o modelo por 100 épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkDIAj98nRBR",
        "outputId": "ccf1e881-c7be-42cb-dbde-42a4ed7b484e"
      },
      "source": [
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1207.8525\n",
            "Epoch [20/100], Loss: 2910.1326\n",
            "Epoch [30/100], Loss: 4431.2192\n",
            "Epoch [40/100], Loss: 8262.8174\n",
            "Epoch [50/100], Loss: 514.2155\n",
            "Epoch [60/100], Loss: 2835.3926\n",
            "Epoch [70/100], Loss: 3178.7805\n",
            "Epoch [80/100], Loss: 1138.8816\n",
            "Epoch [90/100], Loss: 7506.2847\n",
            "Epoch [100/100], Loss: 2833.5955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhHHcKBZoV23"
      },
      "source": [
        "Vamos agora gerar previsões usando o modelo atual e verificar se elas estão próximas dos alvos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBodLw55oaWo",
        "outputId": "526dcda1-6400-4247-b925-1dada1e101d1"
      },
      "source": [
        "y_pred = model(X)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[170.8102,  31.5935,  56.7974],\n",
              "        [114.3646,  21.7443,  37.5852],\n",
              "        [ 97.3198,  22.1558,  31.5281],\n",
              "        [108.4137,  21.8234,  36.5037],\n",
              "        [161.0303,  31.3834,  53.9221],\n",
              "        [105.7592,  20.0864,  35.1214],\n",
              "        [105.0393,  20.5671,  35.1499],\n",
              "        [131.8449,  24.6832,  44.0684],\n",
              "        [211.9275,  39.5276,  71.5569],\n",
              "        [245.6161,  52.5314,  79.0030],\n",
              "        [123.4156,  25.2463,  41.7954],\n",
              "        [215.6799,  42.3097,  71.2874],\n",
              "        [221.9497,  43.1886,  73.6459],\n",
              "        [ 49.5798,  10.5511,  15.8456],\n",
              "        [ 72.1806,  14.5508,  24.0879],\n",
              "        [215.4419,  42.2556,  71.0624],\n",
              "        [ 62.3573,  12.3629,  20.7875],\n",
              "        [241.9433,  45.0878,  80.7330],\n",
              "        [236.0274,  44.6113,  79.0639],\n",
              "        [116.1407,  21.4632,  38.5114]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare o tensor acima com o tensor de alvo exibido abaixo."
      ],
      "metadata": {
        "id": "KatLYM7u9Y7X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OYed8LWofcp",
        "outputId": "1f2ba7ee-e03b-4d35-c4ca-9ec40b2942e4"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[191.,  36.,  50.],\n",
              "        [189.,  37.,  52.],\n",
              "        [193.,  38.,  58.],\n",
              "        [162.,  35.,  62.],\n",
              "        [189.,  35.,  46.],\n",
              "        [182.,  36.,  56.],\n",
              "        [211.,  38.,  56.],\n",
              "        [167.,  34.,  60.],\n",
              "        [176.,  31.,  74.],\n",
              "        [154.,  33.,  56.],\n",
              "        [169.,  34.,  50.],\n",
              "        [166.,  33.,  52.],\n",
              "        [154.,  34.,  64.],\n",
              "        [247.,  46.,  50.],\n",
              "        [193.,  36.,  46.],\n",
              "        [202.,  37.,  62.],\n",
              "        [176.,  37.,  54.],\n",
              "        [157.,  32.,  52.],\n",
              "        [156.,  33.,  54.],\n",
              "        [138.,  33.,  68.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PA6mG8SonTQ"
      },
      "source": [
        "De fato, as previsões estão bem próximas dos alvos. Treinamos um modelo razoavelmente bom para prever o perfil fisiológico de um indivíduo, dado que sabemos seu perfil de realização de exercícios físicos.\n",
        "\n",
        "O código abaixo exemplifica de que forma o modelo pode ser usado para fazer predições sobre novos indivíduos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPErkTiVo4EH",
        "outputId": "4fa786cd-a29a-47a7-e53f-2182d7726065"
      },
      "source": [
        "model(torch.tensor([[6., 152., 59.]])) # inferência"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[159.6112,  29.8985,  53.0825]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}